{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL = 30\n",
    "\n",
    "features = [\"packets\", \"bytes\", \"flows\", \"packets/flows\", \"bytes/flows\", \"bytes/packets\", \"flows/(bytes/packets)\", \"nodes\"]\n",
    "\n",
    "filenames = glob(Path(f'interval{INTERVAL}_reconstructed_STL_trend/200702111400/*/*').__str__())\n",
    "targetFilename = filenames[0].replace(f'interval{INTERVAL}_reconstructed_STL_trend', f'interval{INTERVAL}_reconstructed_STL_trend_ts')\n",
    "dirname = os.path.join(*os.path.dirname(targetFilename).split(os.path.sep)[:-1])\n",
    "targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "if os.path.exists(targetFilename):\n",
    "    exit()\n",
    "\n",
    "timeseries = {}\n",
    "for feature in features:\n",
    "    result = {}\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            lines = f.readlines()\n",
    "            header, data = lines[0], lines[1:]\n",
    "            index = header.strip().split(',').index(feature)\n",
    "            value = [float(line.split(',')[index]) for line in data]\n",
    "        column = os.path.splitext(os.path.basename(filename))[0].split('-')[1]\n",
    "        result[column] = value\n",
    "        \n",
    "    timeseries[feature] = result\n",
    "\n",
    "os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist())\n",
    "np.save(targetFilename, pyts_dataset)\n",
    "\n",
    "with open(os.path.join(f'interval{INTERVAL}_reconstructed_STL_trend_ts/200702111400', 'timeseries_dictionary.json'), 'w') as f:\n",
    "    json.dump(timeseries, f, indent=4)\n",
    "\n",
    "sampleFilename = os.path.splitext(targetFilename)[0] + \"_sample.txt\"\n",
    "featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "\n",
    "with open(sampleFilename, \"w\") as f:\n",
    "    f.write('\\n'.join(list(timeseries[features[0]].keys())))\n",
    "    \n",
    "with open(featureFilename, \"w\") as f:\n",
    "    f.write('\\n'.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102925, 8, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyts_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL = 30\n",
    "\n",
    "if 'timeseries' not in locals():\n",
    "    with open(os.path.join(f'interval{INTERVAL}_reconstructed_STL_trend_ts/200702111400', 'timeseries_dictionary.json')) as f:\n",
    "        timeseries = json.load(f)\n",
    "\n",
    "features = [\"packets\", \"bytes\", \"flows\", \"packets/flows\", \"bytes/flows\", \"bytes/packets\", \"flows/(bytes/packets)\", \"nodes\"]\n",
    "filenames = glob(Path(f'interval{INTERVAL}_reconstructed_STL_trend/200702111400/*/*').__str__())\n",
    "targetFilename = filenames[0].replace(f'interval{INTERVAL}_reconstructed_STL_trend', f'interval{INTERVAL}_reconstructed_STL_trend_ts_feature')\n",
    "\n",
    "for feature in combinations(features, 2):\n",
    "    dirname = os.path.join(*os.path.dirname(targetFilename).split(os.path.sep)[:-1], f\"{feature[0].replace('/', '_')}-{feature[1].replace('/', '_')}\")\n",
    "    targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "    if os.path.exists(targetFilename):\n",
    "        continue\n",
    "    \n",
    "    partial_timeseries = {key: value for key, value in timeseries.items() if key in feature}\n",
    "    \n",
    "    os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "    pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(partial_timeseries)).tolist())\n",
    "    np.save(targetFilename, pyts_dataset)\n",
    "    \n",
    "    featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "\n",
    "    with open(featureFilename, \"w\") as f:\n",
    "        f.write('\\n'.join(feature))\n",
    "    \n",
    "    del partial_timeseries, pyts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load(\"reconstructed_STL_trend_ts/200702111400/pyts_dataset.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 12 samples, 8 features, 901 timestamps\n",
    "# np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tslearn.utils import from_pyts_dataset\n",
    "# from_pyts_dataset(np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist())).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d02331cd1603ec76c6a0d691d59c880477777fc72f4efeafcd9cb0c05515e5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
