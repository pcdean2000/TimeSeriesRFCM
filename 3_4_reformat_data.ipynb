{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "INTERVAL = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_column(filename, feature):\n",
    "#     print(\"\\t\\tFile: \", filename, \" \" * 5, end=\"\\r\")\n",
    "#     value = pd.read_parquet(filename, columns=[feature])[feature].to_list()\n",
    "#     column = os.path.splitext(os.path.basename(filename))[0]\n",
    "#     return column, value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create src combinations of timeseries feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"packets\", \"bytes\", \"flows\", \"bytes/packets\", \"flows/(bytes/packets)\", \"nDstIP\", \"nSrcPort\", \"nDstPort\"]\n",
    "\n",
    "original_prefix = f'pch/20230329-20230331/interval_{INTERVAL}_src_feature'\n",
    "# extended_prefix = [\"_reconstructed_STL_trend\", \"_reconstructed_STL_seasonal\", \"_reconstructed_STL_combined\", \"_reconstructed_STL_detrend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix:  pch/20230330/interval_60_src_feature\n",
      "\tFeature:  packets\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  bytes\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  flows\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  bytes/packets\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  flows/(bytes/packets)\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  nDstIP\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  nSrcPort\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n",
      "\tFeature:  nDstPort\n",
      "\t\tFile:  pch\\20230330\\interval_60_src_feature\\99.86.178.54.parquet         \n"
     ]
    }
   ],
   "source": [
    "for prefix in [original_prefix]:\n",
    "    print(\"Prefix: \", prefix)\n",
    "    dirname = os.path.join(\"timeseries\", prefix)\n",
    "    targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "    sampleFilename = os.path.splitext(targetFilename)[0] + \"_sample.txt\"\n",
    "    featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "    if os.path.exists(featureFilename):\n",
    "        continue\n",
    "\n",
    "    timeseries = {}\n",
    "    for feature in features:\n",
    "        print(\"\\tFeature: \", feature)\n",
    "        result = {}\n",
    "        for filename in glob(Path(f'{prefix}/*').__str__()):\n",
    "            print(\"\\t\\tFile: \", filename, \" \" * 5, end=\"\\r\")\n",
    "            value = pd.read_parquet(filename, columns=[feature])[feature].to_list()\n",
    "            column = os.path.splitext(os.path.basename(filename))[0]\n",
    "            result[column] = value\n",
    "        print()\n",
    "            \n",
    "        timeseries[feature] = result\n",
    "\n",
    "    os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "    pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist())\n",
    "    np.save(targetFilename, pyts_dataset)\n",
    "\n",
    "    with open(os.path.join(dirname, 'timeseries_dictionary.pickle'), 'wb') as f:\n",
    "        pickle.dump(timeseries, f)\n",
    "\n",
    "    with open(sampleFilename, \"w\") as f:\n",
    "        f.write('\\n'.join(list(timeseries[features[0]].keys())))\n",
    "        \n",
    "    with open(featureFilename, \"w\") as f:\n",
    "        f.write('\\n'.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix:  pch/20230330/interval_60_src_feature\n",
      "\tFeature:  ('packets', 'bytes')\n",
      "\tFeature:  ('packets', 'flows')\n",
      "\tFeature:  ('packets', 'bytes/packets')\n",
      "\tFeature:  ('packets', 'flows/(bytes/packets)')\n",
      "\tFeature:  ('packets', 'nDstIP')\n",
      "\tFeature:  ('packets', 'nSrcPort')\n",
      "\tFeature:  ('packets', 'nDstPort')\n",
      "\tFeature:  ('bytes', 'flows')\n",
      "\tFeature:  ('bytes', 'bytes/packets')\n",
      "\tFeature:  ('bytes', 'flows/(bytes/packets)')\n",
      "\tFeature:  ('bytes', 'nDstIP')\n",
      "\tFeature:  ('bytes', 'nSrcPort')\n",
      "\tFeature:  ('bytes', 'nDstPort')\n",
      "\tFeature:  ('flows', 'bytes/packets')\n",
      "\tFeature:  ('flows', 'flows/(bytes/packets)')\n",
      "\tFeature:  ('flows', 'nDstIP')\n",
      "\tFeature:  ('flows', 'nSrcPort')\n",
      "\tFeature:  ('flows', 'nDstPort')\n",
      "\tFeature:  ('bytes/packets', 'flows/(bytes/packets)')\n",
      "\tFeature:  ('bytes/packets', 'nDstIP')\n",
      "\tFeature:  ('bytes/packets', 'nSrcPort')\n",
      "\tFeature:  ('bytes/packets', 'nDstPort')\n",
      "\tFeature:  ('flows/(bytes/packets)', 'nDstIP')\n",
      "\tFeature:  ('flows/(bytes/packets)', 'nSrcPort')\n",
      "\tFeature:  ('flows/(bytes/packets)', 'nDstPort')\n",
      "\tFeature:  ('nDstIP', 'nSrcPort')\n",
      "\tFeature:  ('nDstIP', 'nDstPort')\n",
      "\tFeature:  ('nSrcPort', 'nDstPort')\n"
     ]
    }
   ],
   "source": [
    "for prefix in [original_prefix]:\n",
    "    print(\"Prefix: \", prefix)\n",
    "    dirname = os.path.join(\"timeseries\", prefix)\n",
    "    if \"timeseries\" not in locals():\n",
    "        with open(os.path.join(dirname, 'timeseries_dictionary.pickle'), 'rb') as f:\n",
    "            timeseries = pickle.load(f)\n",
    "\n",
    "    targetDirname = dirname.replace(\"timeseries\", \"timeseries_feature\")\n",
    "\n",
    "    for feature in combinations(features, 2):\n",
    "        print(\"\\tFeature: \", feature)\n",
    "        dirname = os.path.join(targetDirname, f\"{feature[0].replace('/', '_')}-{feature[1].replace('/', '_')}\")\n",
    "        targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "        featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "        if os.path.exists(featureFilename):\n",
    "            continue\n",
    "        \n",
    "        partial_timeseries = {key: value for key, value in timeseries.items() if key in feature}\n",
    "        \n",
    "        os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "        pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(partial_timeseries)).tolist())\n",
    "        np.save(targetFilename, pyts_dataset)\n",
    "        \n",
    "        with open(featureFilename, \"w\") as f:\n",
    "            f.write('\\n'.join(feature))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dst combinations of timeseries feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"packets\", \"bytes\", \"flows\", \"bytes/packets\", \"flows/(bytes/packets)\", \"nSrcIP\", \"nSrcPort\", \"nDstPort\"]\n",
    "\n",
    "original_prefix = f'pch/20230329-20230331/interval_{INTERVAL}_dst_feature'\n",
    "# extended_prefix = [\"_reconstructed_STL_trend\", \"_reconstructed_STL_seasonal\", \"_reconstructed_STL_combined\", \"_reconstructed_STL_detrend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix:  pch/20230330/interval_60_dst_feature\n",
      "\tFeature:  packets\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  bytes\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  flows\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  bytes/packets\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  flows/(bytes/packets)\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  nSrcIP\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  nSrcPort\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n",
      "\tFeature:  nDstPort\n",
      "\t\tFile:  pch\\20230330\\interval_60_dst_feature\\99.86.178.54.parguet         \n"
     ]
    }
   ],
   "source": [
    "for prefix in [original_prefix]:\n",
    "    print(\"Prefix: \", prefix)\n",
    "    dirname = os.path.join(\"timeseries\", prefix)\n",
    "    targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "    sampleFilename = os.path.splitext(targetFilename)[0] + \"_sample.txt\"\n",
    "    featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "    if os.path.exists(featureFilename):\n",
    "        continue\n",
    "\n",
    "    timeseries = {}\n",
    "    for feature in features:\n",
    "        print(\"\\tFeature: \", feature)\n",
    "        result = {}\n",
    "        for filename in glob(Path(f'{prefix}/*').__str__()):\n",
    "            print(\"\\t\\tFile: \", filename, \" \" * 5, end=\"\\r\")\n",
    "            value = pd.read_parquet(filename, columns=[feature])[feature].to_list()\n",
    "            column = os.path.splitext(os.path.basename(filename))[0]\n",
    "            result[column] = value\n",
    "        print()\n",
    "            \n",
    "        timeseries[feature] = result\n",
    "\n",
    "    os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "    pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist())\n",
    "    np.save(targetFilename, pyts_dataset)\n",
    "\n",
    "    with open(os.path.join(dirname, 'timeseries_dictionary.pickle'), 'wb') as f:\n",
    "        pickle.dump(timeseries, f)\n",
    "\n",
    "    with open(sampleFilename, \"w\") as f:\n",
    "        f.write('\\n'.join(list(timeseries[features[0]].keys())))\n",
    "        \n",
    "    with open(featureFilename, \"w\") as f:\n",
    "        f.write('\\n'.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix:  pch/20230330/interval_60_dst_feature\n",
      "\tfeature:  ('packets', 'bytes')\n",
      "\tfeature:  ('packets', 'flows')\n",
      "\tfeature:  ('packets', 'bytes/packets')\n",
      "\tfeature:  ('packets', 'flows/(bytes/packets)')\n",
      "\tfeature:  ('packets', 'nSrcIP')\n",
      "\tfeature:  ('packets', 'nSrcPort')\n",
      "\tfeature:  ('packets', 'nDstPort')\n",
      "\tfeature:  ('bytes', 'flows')\n",
      "\tfeature:  ('bytes', 'bytes/packets')\n",
      "\tfeature:  ('bytes', 'flows/(bytes/packets)')\n",
      "\tfeature:  ('bytes', 'nSrcIP')\n",
      "\tfeature:  ('bytes', 'nSrcPort')\n",
      "\tfeature:  ('bytes', 'nDstPort')\n",
      "\tfeature:  ('flows', 'bytes/packets')\n",
      "\tfeature:  ('flows', 'flows/(bytes/packets)')\n",
      "\tfeature:  ('flows', 'nSrcIP')\n",
      "\tfeature:  ('flows', 'nSrcPort')\n",
      "\tfeature:  ('flows', 'nDstPort')\n",
      "\tfeature:  ('bytes/packets', 'flows/(bytes/packets)')\n",
      "\tfeature:  ('bytes/packets', 'nSrcIP')\n",
      "\tfeature:  ('bytes/packets', 'nSrcPort')\n",
      "\tfeature:  ('bytes/packets', 'nDstPort')\n",
      "\tfeature:  ('flows/(bytes/packets)', 'nSrcIP')\n",
      "\tfeature:  ('flows/(bytes/packets)', 'nSrcPort')\n",
      "\tfeature:  ('flows/(bytes/packets)', 'nDstPort')\n",
      "\tfeature:  ('nSrcIP', 'nSrcPort')\n",
      "\tfeature:  ('nSrcIP', 'nDstPort')\n",
      "\tfeature:  ('nSrcPort', 'nDstPort')\n"
     ]
    }
   ],
   "source": [
    "for prefix in [original_prefix]:\n",
    "    print(\"prefix: \", prefix)\n",
    "    dirname = os.path.join(\"timeseries\", prefix)\n",
    "    with open(os.path.join(dirname, 'timeseries_dictionary.pickle'), 'rb') as f:\n",
    "        timeseries = pickle.load(f)\n",
    "\n",
    "    targetDirname = dirname.replace(\"timeseries\", \"timeseries_feature\")\n",
    "\n",
    "    for feature in combinations(features, 2):\n",
    "        print(\"\\tfeature: \", feature)\n",
    "        dirname = os.path.join(targetDirname, f\"{feature[0].replace('/', '_')}-{feature[1].replace('/', '_')}\")\n",
    "        targetFilename = os.path.join(dirname, \"pyts_dataset.npy\")\n",
    "        featureFilename = os.path.splitext(targetFilename)[0] + \"_feature.txt\"\n",
    "        if os.path.exists(featureFilename):\n",
    "            continue\n",
    "        \n",
    "        partial_timeseries = {key: value for key, value in timeseries.items() if key in feature}\n",
    "        \n",
    "        os.makedirs(os.path.dirname(targetFilename), exist_ok=True)\n",
    "        pyts_dataset = np.array(np.array(pd.DataFrame.from_dict(partial_timeseries)).tolist())\n",
    "        np.save(targetFilename, pyts_dataset)\n",
    "\n",
    "        with open(featureFilename, \"w\") as f:\n",
    "            f.write('\\n'.join(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load(\"reconstructed_STL_trend_ts/200702111400/pyts_dataset.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 12 samples, 8 features, 901 timestamps\n",
    "# np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tslearn.utils import from_pyts_dataset\n",
    "# from_pyts_dataset(np.array(np.array(pd.DataFrame.from_dict(timeseries)).tolist())).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d02331cd1603ec76c6a0d691d59c880477777fc72f4efeafcd9cb0c05515e5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
