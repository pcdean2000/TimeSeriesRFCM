{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsezeeklogs import ParseZeekLogs\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log 檔轉成 csv 檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"zeek_csv\", exist_ok=True)\n",
    "\n",
    "for log_file in glob(\"zeek/*.log\"):\n",
    "    out_csv = log_file.replace(\".log\", \".csv\").replace(\"zeek\", \"zeek_csv\")\n",
    "    with open(out_csv,\"w\") as outfile:\n",
    "        zeekLogs = ParseZeekLogs(log_file, output_format=\"csv\")\n",
    "        outfile.write(zeekLogs.get_fields() + \"\\n\")\n",
    "        for log_record in zeekLogs:\n",
    "            if log_record is not None:\n",
    "                outfile.write(log_record + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conn 和 flowmeter 合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pd.read_csv(\"zeek_csv/conn.csv\")\n",
    "flowmeter = pd.read_csv(\"zeek_csv/flowmeter.csv\")\n",
    "\n",
    "pd.merge(conn, flowmeter, on=\"uid\").to_csv(\"zeek_csv/conn_flowmeter.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "排除 analyzer 和 dns 的流量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_flowmeter = pd.read_csv(\"zeek_csv/conn_flowmeter.csv\", low_memory=False)\n",
    "analyzer = pd.read_csv(\"zeek_csv/analyzer.csv\")\n",
    "dns = pd.read_csv(\"zeek_csv/dns.csv\")\n",
    "# weird = pd.read_csv(\"zeek_csv/weird.csv\")\n",
    "\n",
    "conn_flowmeter = conn_flowmeter[~conn_flowmeter.uid.isin(analyzer.uid)]\n",
    "conn_flowmeter = conn_flowmeter[~conn_flowmeter.uid.isin(dns.uid)]\n",
    "# conn_flowmeter = conn_flowmeter[~conn_flowmeter.uid.isin(weird.uid)]\n",
    "\n",
    "conn_flowmeter.to_csv(\"zeek_csv/filtered_conn_flowmeter.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "濾掉 netflow 中被 zeek 歸類為 analyzer 和 dns 的 flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflow = pd.read_csv(\"netflow/200702111400.csv\", low_memory=False)\n",
    "analyzer = pd.read_csv(\"zeek_csv/analyzer.csv\")\n",
    "dns = pd.read_csv(\"zeek_csv/dns.csv\")\n",
    "\n",
    "analyzer_dns = pd.merge(analyzer[[\"id.orig_h\",\"id.resp_h\",\"id.orig_p\",\"id.resp_p\"]], dns[[\"id.orig_h\",\"id.resp_h\",\"id.orig_p\",\"id.resp_p\"]], how=\"outer\")\n",
    "analyzer_dns.columns = [\"sa\",\"da\",\"sp\",\"dp\"]\n",
    "\n",
    "netflow_filtered = pd.merge(netflow, analyzer_dns, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "netflow_filtered.to_csv(\"netflow/200702111400_filtered.csv\", index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d02331cd1603ec76c6a0d691d59c880477777fc72f4efeafcd9cb0c05515e5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
