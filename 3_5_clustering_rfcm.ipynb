{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from rfcm import RFCM\n",
    "\n",
    "INTERVAL = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropna(nparray):\n",
    "    if isinstance(nparray[0], np.ndarray):\n",
    "        return np.array([dropna(x) for x in nparray])\n",
    "    else:\n",
    "        return nparray[~np.isnan(nparray)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir:  timeseries_feature\\pch\\20230329\\interval_15_src_feature\\bytes-bytes_packets\n",
      "\tPyts dataset shape:  (1973, 2, 61)\n",
      "----- Start size insensitive rfcm -----\n",
      "Center: [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]                                ]]\n",
      "Center: [[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]\n",
      " [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan]                                           ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"g:\\Github\\TimeSeriesRFCM\\rfcm.py\", line 42, in do_one_calc_dtw\n    cost = dtw(line[index].get_data(), center_node[index].get_data(), dist=distance)\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyts\\metrics\\dtw.py\", line 1007, in dtw\n    _check_input_dtw(x, y, precomputed_cost, dist, method)\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyts\\metrics\\dtw.py\", line 66, in _check_input_dtw\n    y = check_array(y, ensure_2d=False, dtype='float64')\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 919, in check_array\n    _assert_all_finite(\n  File \"c:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input contains NaN.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mPyts dataset shape: \u001b[39m\u001b[39m\"\u001b[39m, pyts_dataset\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      9\u001b[0m model \u001b[39m=\u001b[39m RFCM(n_clusters\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mfit(pyts_dataset)\n\u001b[0;32m     11\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlabels_\n\u001b[0;32m     12\u001b[0m np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dirname, \u001b[39m\"\u001b[39m\u001b[39mrfcm_label.npy\u001b[39m\u001b[39m\"\u001b[39m), y_pred)\n",
      "File \u001b[1;32mg:\\Github\\TimeSeriesRFCM\\rfcm.py:202\u001b[0m, in \u001b[0;36mRFCM.fit\u001b[1;34m(self, data, y, sample_weight)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     sample_weight \u001b[39m=\u001b[39m skv\u001b[39m.\u001b[39m_check_sample_weight(sample_weight, data)\n\u001b[1;32m--> 202\u001b[0m U, center \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_noise_resistant_rfcm(\n\u001b[0;32m    203\u001b[0m     data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_clusters, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpo, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp)\n\u001b[0;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_ \u001b[39m=\u001b[39m center\n\u001b[0;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_cluster_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mg:\\Github\\TimeSeriesRFCM\\rfcm.py:142\u001b[0m, in \u001b[0;36mRFCM._noise_resistant_rfcm\u001b[1;34m(self, data, n_clusters, epsilon, expo, alpha, max_iter, p)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_noise_resistant_rfcm\u001b[39m(\u001b[39mself\u001b[39m, data, n_clusters, epsilon, expo, alpha, max_iter, p):\n\u001b[1;32m--> 142\u001b[0m     U, center \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_size_insensitive_rfcm(\n\u001b[0;32m    143\u001b[0m         data, n_clusters, epsilon, expo, max_iter, p)\n\u001b[0;32m    145\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m----- Start noise resistant rfcm -----\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    146\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[0;32m    147\u001b[0m         \u001b[39m# distance part of the U update equation\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Github\\TimeSeriesRFCM\\rfcm.py:112\u001b[0m, in \u001b[0;36mRFCM._size_insensitive_rfcm\u001b[1;34m(self, data, n_clusters, epsilon, expo, max_iter, p)\u001b[0m\n\u001b[0;32m    108\u001b[0m interaction_reduction \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msubtract(\n\u001b[0;32m    109\u001b[0m     \u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mtake_along_axis(relative_size\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39mexpand_dims(index_array, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT  \u001b[39m# The interaction reduction, Rho_j in the paper\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# distance part of the U update equation\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m dist_part \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_dtw(data, center) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (expo \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    114\u001b[0m \u001b[39m# coefficient part of the U update equation\u001b[39;00m\n\u001b[0;32m    115\u001b[0m coef_part \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpower(\n\u001b[0;32m    116\u001b[0m     \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mmultiply(membership, np\u001b[39m.\u001b[39mdivide(\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mpower(n_data, p \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))), (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (expo \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)))\n",
      "File \u001b[1;32mg:\\Github\\TimeSeriesRFCM\\rfcm.py:60\u001b[0m, in \u001b[0;36mRFCM.calc_dtw\u001b[1;34m(self, data, center)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m center_node \u001b[39min\u001b[39;00m center:\n\u001b[0;32m     51\u001b[0m     \u001b[39m# dist_center_node = []\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[39m# for line in data:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[39m#         dist_feature.append(cost)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[39m#     dist_center_node.append(np.linalg.norm(np.array(dist_feature)))\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(processes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs) \u001b[39mas\u001b[39;00m pool:\n\u001b[1;32m---> 60\u001b[0m         dist_center_node \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mstarmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_one_calc_dtw, [(line, center_node) \u001b[39mfor\u001b[39;49;00m line \u001b[39min\u001b[39;49;00m data])\n\u001b[0;32m     61\u001b[0m     dist\u001b[39m.\u001b[39mappend(dist_center_node)\n\u001b[0;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(dist)\n",
      "File \u001b[1;32mc:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    370\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\pcdea\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "for direction in [\"src\"]:\n",
    "    for dirname in glob(Path(f'timeseries_feature/pch/20230329/interval_{INTERVAL}_{direction}*/*').__str__()):\n",
    "        print(\"Dir: \", dirname)\n",
    "        if os.path.exists(os.path.join(dirname, \"rfcm_label.npy\")):\n",
    "            continue\n",
    "        pyts_dataset = np.load(os.path.join(dirname, \"pyts_dataset.npy\"))\n",
    "        pyts_dataset = dropna(pyts_dataset)\n",
    "        print(\"\\tPyts dataset shape: \", pyts_dataset.shape)\n",
    "        model = RFCM(n_clusters=10, max_iter=10, random_state=0, n_jobs=4, epsilon=1e-3)\n",
    "        model.fit(pyts_dataset)\n",
    "        y_pred = model.labels_\n",
    "        np.save(os.path.join(dirname, \"rfcm_label.npy\"), y_pred)\n",
    "        print(\"\\tRFCM label shape: \", y_pred.shape)\n",
    "        del pyts_dataset, model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EmptyClusterError(Exception):\n",
    "#     def __init__(self, message=\"\"):\n",
    "#         super().__init__()\n",
    "#         self.message = message\n",
    "\n",
    "#     def __str__(self):\n",
    "#         if len(self.message) > 0:\n",
    "#             suffix = \" (%s)\" % self.message\n",
    "#         else:\n",
    "#             suffix = \"\"\n",
    "#         return \"Cluster assignments lead to at least one empty cluster\" + \\\n",
    "#                suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSeriesCentroidBasedClusteringMixin:\n",
    "#     \"\"\"Mixin class for centroid-based clustering of time series.\"\"\"\n",
    "#     def _post_fit(self, X_fitted, centroids, inertia):\n",
    "#         if np.isfinite(inertia) and (centroids is not None):\n",
    "#             self.cluster_centers_ = centroids\n",
    "#             self._assign(X_fitted)\n",
    "#             self._X_fit = X_fitted\n",
    "#             self.inertia_ = inertia\n",
    "#         else:\n",
    "#             self._X_fit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _check_initial_guess(init, n_clusters):\n",
    "#     if hasattr(init, '__array__'):\n",
    "#         assert init.shape[0] == n_clusters, \\\n",
    "#             \"Initial guess index array must contain {} samples,\" \\\n",
    "#             \" {} given\".format(n_clusters, init.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _k_init_metric(X, n_clusters, cdist_metric, random_state, n_local_trials=None):\n",
    "#     n_samples, n_timestamps, n_features = X.shape\n",
    "\n",
    "#     centers = np.empty((n_clusters, n_timestamps, n_features), dtype=X.dtype)\n",
    "\n",
    "#     # Set the number of local seeding trials if none is given\n",
    "#     if n_local_trials is None:\n",
    "#         # This is what Arthur/Vassilvitskii tried, but did not report\n",
    "#         # specific results for other than mentioning in the conclusion\n",
    "#         # that it helped.\n",
    "#         n_local_trials = 2 + int(np.log(n_clusters))\n",
    "\n",
    "#     # Pick first center randomly\n",
    "#     center_id = random_state.randint(n_samples)\n",
    "#     centers[0] = X[center_id]\n",
    "\n",
    "#     # Initialize list of closest distances and calculate current potential\n",
    "#     closest_dist_sq = cdist_metric(centers[0, np.newaxis], X) ** 2\n",
    "#     current_pot = closest_dist_sq.sum()\n",
    "\n",
    "#     # Pick the remaining n_clusters-1 points\n",
    "#     for c in range(1, n_clusters):\n",
    "#         # Choose center candidates by sampling with probability proportional\n",
    "#         # to the squared distance to the closest existing center\n",
    "#         rand_vals = random_state.random_sample(n_local_trials) * current_pot\n",
    "#         candidate_ids = np.searchsorted(stable_cumsum(closest_dist_sq), rand_vals)\n",
    "#         # XXX: numerical imprecision can result in a candidate_id out of range\n",
    "#         np.clip(candidate_ids, None, closest_dist_sq.size - 1, out=candidate_ids)\n",
    "\n",
    "#         # Compute distances to center candidates\n",
    "#         distance_to_candidates = cdist_metric(X[candidate_ids], X) ** 2\n",
    "\n",
    "#         # update closest distances squared and potential for each candidate\n",
    "#         np.minimum(closest_dist_sq, distance_to_candidates, out=distance_to_candidates)\n",
    "#         candidates_pot = distance_to_candidates.sum(axis=1)\n",
    "\n",
    "#         # Decide which candidate is the best\n",
    "#         best_candidate = np.argmin(candidates_pot)\n",
    "#         current_pot = candidates_pot[best_candidate]\n",
    "#         closest_dist_sq = distance_to_candidates[best_candidate]\n",
    "#         best_candidate = candidate_ids[best_candidate]\n",
    "\n",
    "#         # Permanently add best center candidate found in local tries\n",
    "#         centers[c] = X[best_candidate]\n",
    "\n",
    "#     return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSeriesRFCM(TransformerMixin, ClusterMixin, TimeSeriesCentroidBasedClusteringMixin, BaseModelPackage, TimeSeriesBaseEstimator):\n",
    "#     def __init__(self, n_clusters=3, max_iter=50, tol=1e-6, n_init=1, metric=\"softdtw\", max_iter_barycenter=100, metric_params=None, n_jobs=None, dtw_inertia=False, verbose=0, random_state=None, init='RFCM') -> None:\n",
    "#         super().__init__()\n",
    "#         self.n_clusters = n_clusters\n",
    "#         self.max_iter = max_iter\n",
    "#         self.tol = tol\n",
    "#         self.n_init = n_init\n",
    "#         self.metric = metric\n",
    "#         self.max_iter_barycenter = max_iter_barycenter\n",
    "#         self.metric_params = metric_params\n",
    "#         self.n_jobs = n_jobs\n",
    "#         self.dtw_inertia = dtw_inertia\n",
    "#         self.verbose = verbose\n",
    "#         self.random_state = random_state\n",
    "#         self.init = init\n",
    "        \n",
    "#     def _is_fitted(self):\n",
    "#         check_is_fitted(self, [\"cluster_centers_\"])\n",
    "#         return True\n",
    "    \n",
    "#     def _get_metric_params(self):\n",
    "#         if self.metric_params is None:\n",
    "#             metric_params = {}\n",
    "#         else:\n",
    "#             metric_params = self.metric_params.copy()\n",
    "#         if \"n_jobs\" in metric_params:\n",
    "#             del metric_params[\"n_jobs\"]\n",
    "#         return metric_params\n",
    "    \n",
    "#     def _fit_one_init(self, X, x_squared_norms, rs):\n",
    "#         metric_params = self._get_metric_params()\n",
    "#         n_ts, sz, d = X.shape\n",
    "#         if hasattr(self.init, '__array__'):\n",
    "#             self.cluster_centers_ = self.init.copy()\n",
    "#         elif isinstance(self.init, str) and self.init == 'RFCM':\n",
    "#             if self.metric == \"softdtw\":\n",
    "#                 def metric_fun(x, y):\n",
    "#                     return cdist_soft_dtw(x, y, **metric_params)\n",
    "#             else:\n",
    "#                 raise ValueError(\"Incorrect metric: %s (should be one of 'softdtw')\" % self.metric)\n",
    "#             self.cluster_centers_ = _k_init_metric(X, self.n_clusters, cdist_metric=metric_fun, random_state=rs)\n",
    "#             for i in range(self.n_clusters):\n",
    "#                 self.cluster_centers_[i] = X[rs.randint(n_ts)]\n",
    "        \n",
    "#     def _transform(self, X):\n",
    "#         metric_params = self._get_metric_params()\n",
    "#         if self.metric == \"softdtw\":\n",
    "#             return cdist_soft_dtw(X, self.cluster_centers_, **metric_params)\n",
    "#         else:\n",
    "#             raise ValueError(\"Incorrect metric: %s (should be one of 'softdtw')\" % self.metric)\n",
    "        \n",
    "#     def _update_centroids(self, X):\n",
    "#         metric_params = self._get_metric_params()\n",
    "#         for k in \n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         X = check_array(X, allow_nd=True, force_all_finite='allow-nan')\n",
    "        \n",
    "#         if hasattr(self.init, '__array__'):\n",
    "#             X = check_dims(X, X_fit_dims=self.init.shape, extend=True, check_n_features_only=(self.metric != \"euclidean\"))\n",
    "            \n",
    "#         self.labels_ = None\n",
    "#         self.inertia_ = np.inf\n",
    "#         self.cluster_centers_ = None\n",
    "#         self._X_fit = None\n",
    "#         self._squared_inertia = True\n",
    "\n",
    "#         self.n_iter_ = 0\n",
    "\n",
    "#         max_attempts = max(self.n_init, 10)\n",
    "\n",
    "#         X_ = to_time_series_dataset(X)\n",
    "#         rs = check_random_state(self.random_state)\n",
    "        \n",
    "#         x_squared_norms = None\n",
    "#         _check_initial_guess(self.init, self.n_clusters)\n",
    "        \n",
    "#         best_correct_centroids = None\n",
    "#         min_inertia = np.inf\n",
    "#         n_successful = 0\n",
    "#         n_attempts = 0\n",
    "#         while n_successful < self.n_init and n_attempts < max_attempts:\n",
    "#             try:\n",
    "#                 if self.verbose and self.n_init > 1:\n",
    "#                     print(\"Init %d\" % (n_successful + 1))\n",
    "#                 n_attempts += 1\n",
    "#                 self._fit_one_init(X_, x_squared_norms, rs)\n",
    "#                 if self.inertia_ < min_inertia:\n",
    "#                     best_correct_centroids = self.cluster_centers_.copy()\n",
    "#                     min_inertia = self.inertia_\n",
    "#                     self.n_iter_ = self._iter\n",
    "#                 n_successful += 1\n",
    "#             except EmptyClusterError:\n",
    "#                 if self.verbose:\n",
    "#                     print(\"Resumed because of empty cluster\")\n",
    "#         self._post_fit(X_, best_correct_centroids, min_inertia)\n",
    "#         return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d02331cd1603ec76c6a0d691d59c880477777fc72f4efeafcd9cb0c05515e5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
